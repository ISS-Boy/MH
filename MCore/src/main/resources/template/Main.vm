#parse("template/macro.vm")
#set($key_serializer = ${MonitorMetadata.StreamConfig.KeySerializer})
#set($value_serializer = ${MonitorMetadata.StreamConfig.ValueSerializer})


public class Main {



    public static final String STORE_NAME1 = "null";
    public static final String STORE_NAME2 = "null";


    public static class CustomRocksDBConfig implements RocksDBConfigSetter {

        @Override
        public void setConfig(final String storeName, final Options options, final Map<String, Object> configs) {
            // Workaround: We must ensure that the parallelism is set to >= 2.  There seems to be a known
            // issue with RocksDB where explicitly setting the parallelism to 1 causes issues (even though
            // 1 seems to be RocksDB's default for this configuration).
            int compactionParallelism = Math.max(Runtime.getRuntime().availableProcessors(), 2);
            // Set number of compaction threads (but not flush threads).
            options.setIncreaseParallelism(compactionParallelism);
        }
    }

    public static void main(String[] args) throws Exception{

        final int restEndpointPort = 8080;
        final String restEndpointHostname = "localhost";
        final String bootstrapServers = "${MonitorMetadata.StreamConfig.BootstrapServer}";
        final String schemaRegistryUrl = "${MonitorMetadata.StreamConfig.SchemaRegistry}";

        System.out.println("Connecting to Kafka cluster via bootstrap servers " + bootstrapServers);
        System.out.println("Connecting to Confluent schema registry at " + schemaRegistryUrl);
        System.out.println("REST endpoint at http://" + restEndpointHostname + ":" + restEndpointPort);

        final KafkaStreams streams = createStreams(bootstrapServers,
            schemaRegistryUrl,
            restEndpointPort,
            "/tmp/streams-example");

        streams.cleanUp();

        streams.start();

    }




    static KafkaStreams createStreams(final String bootstrapServers,
                                    final String schemaRegistryUrl,
                                    final int applicationServerPort,
                                    final String stateDir) throws IOException {

        final Properties streamsConfiguration = new Properties();

        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, "${MonitorMetadata.StreamConfig.ApplicationId}");
        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        streamsConfiguration.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, schemaRegistryUrl);
        streamsConfiguration.put(StreamsConfig.APPLICATION_SERVER_CONFIG, "localhost:" + applicationServerPort);
        streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, stateDir);
        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,#if(${key_serializer} == "AVRO")SpecificAvroSerde.class #else Serdes.${key_serializer}().getClass().getName()#end);
        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, #if(${value_serializer} == "AVRO")SpecificAvroSerde.class #else Serdes.${value_serializer}().getClass().getName()#end);
        streamsConfiguration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 10 * 1000);

        String metadataMaxAgeMs = System.getProperty(ConsumerConfig.METADATA_MAX_AGE_CONFIG);
        if (metadataMaxAgeMs != null) {
            try {
                int value = Integer.parseInt(metadataMaxAgeMs);
                streamsConfiguration.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, value);
                System.out.println("Set consumer configuration " + ConsumerConfig.METADATA_MAX_AGE_CONFIG +
                        " to " + value);
            } catch (NumberFormatException ignored) {
            }
        }

        final KStreamBuilder builder = new KStreamBuilder();

        final Map<String, String> serdeConfig = Collections.singletonMap(
                AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, schemaRegistryUrl);

        ${MonitorMetadata.DSLCode}
        return new KafkaStreams(builder,streamsConfiguration);
    }
}